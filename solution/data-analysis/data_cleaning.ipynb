{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ada8e0800af80f",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "The cleaning process is organized into sections, each corresponding to a different dataset (`.csv` file). Each section includes the following steps:\n",
    "\n",
    "1. **Data Understanding**: Initial exploration of the dataset.\n",
    "2. **Data Cleaning**: Handling of missing values (NaN), removal of duplicates, setting correct data types, and renaming columns. <br>\n",
    "   *(Optional)* **Deep Clean**: Custom cleaning steps applied to a specific dataset, if necessary.\n",
    "3. **Final Result**: Displays the cleaned dataset and saves it to a new `.csv` file.\n",
    "\n",
    "All the datasets combined have a total size of ~1Gb and can be all uploaded in memory at the same time on almost every PC.\n",
    "\n",
    "First, import the necessary libraries and set up any required options."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.utils import find_matching\n",
    "\n",
    "# Set to True to print cleaned data into new csv\n",
    "PRINT_CSV = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3535d2e877d218a5",
   "metadata": {},
   "source": [
    "## Movies"
   ]
  },
  {
   "cell_type": "code",
   "id": "bfa523a3d71aa334",
   "metadata": {},
   "source": [
    "# Import 'movies.csv' dataset\n",
    "movies_df = pd.read_csv('datasets/movies.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91a7f5cc08f506b1",
   "metadata": {},
   "source": [
    "### 1. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "id": "3fdf6136a09202bf",
   "metadata": {},
   "source": [
    "movies_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f25edf3b61586308",
   "metadata": {},
   "source": [
    "movies_df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "66353feb2d15e0c1",
   "metadata": {},
   "source": [
    "movies_df.dtypes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24564dc69f48117c",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "id": "92ec1ff74b506e2f",
   "metadata": {},
   "source": [
    "# Rename columns\n",
    "movies_df = movies_df.rename(columns={'name': 'title', 'minute': 'duration_in_minutes', 'date': 'release_year'})\n",
    "print(f\"Movies dataset columns: {', '.join(movies_df.columns)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "943d34788f840a4c",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "movies_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5d60bd3bbbcdf43",
   "metadata": {},
   "source": [
    "There are null values in most of the columns.\n",
    "The fields '**release_year**', '**tagline**', '**description**', '**duration_in_minutes**' and '**rating**' don't cause any problems so we'll keep them, but the few movies that are without a title can't be used and will be removed."
   ]
  },
  {
   "cell_type": "code",
   "id": "e64b09d17cd6ac6f",
   "metadata": {},
   "source": [
    "# Removing rows with null title\n",
    "no_title = movies_df[movies_df['title'].isna()]\n",
    "movies_df = movies_df.dropna(subset=['title'])\n",
    "\n",
    "print(\"Movies dataset without title:\")\n",
    "no_title.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "709a95587abbdd3e",
   "metadata": {},
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {movies_df.duplicated().sum()} duplicated rows\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b859e3726529609e",
   "metadata": {},
   "source": [
    "# Setting the correct type for columns\n",
    "movies_df['release_year'] = movies_df['release_year'].astype('Int64')\n",
    "movies_df['duration_in_minutes'] = movies_df['duration_in_minutes'].astype('Int64')\n",
    "movies_df[['release_year', 'duration_in_minutes']].dtypes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "903dbbf0e5d08f7c",
   "metadata": {},
   "source": [
    "# Check if 'id' column has unique values\n",
    "print(f\"'id' duplicates: {movies_df[movies_df['id'].duplicated()].shape[0]}\")\n",
    "movies_df = movies_df.set_index(\"id\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12ecbd6bd4da8000",
   "metadata": {},
   "source": [
    "The '**id**' field is the unique identifier of a movie, so it's been set as the index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de852ea61ae6f48",
   "metadata": {},
   "source": [
    "#### Deep Clean\n",
    "Let's look inside some columns to see most frequent values:"
   ]
  },
  {
   "cell_type": "code",
   "id": "207fa8d6b074b053",
   "metadata": {},
   "source": [
    "movies_df['description'].value_counts().head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a74a60d521aeb637",
   "metadata": {},
   "source": [
    "Many descriptions seem to have a description like \"Plot Unavailable\" or similar instead of a null value. The other fields seem fine.<br>\n",
    "Let's try to fix as many as possible (fixing only the most frequent variation, not 100% accurate)."
   ]
  },
  {
   "cell_type": "code",
   "id": "29ea2050d5268983",
   "metadata": {},
   "source": [
    "from utils.utils import null_movie_description_keywords\n",
    "\n",
    "# Find null description variation\n",
    "result = find_matching(movies_df, 'description', null_movie_description_keywords, max_length=30)\n",
    "matches = result.copy()\n",
    "\n",
    "# Fill with NaN values the result obtained\n",
    "result['description'] = np.nan\n",
    "\n",
    "# Manual check to be sure to not overwrite real descriptions\n",
    "matches['description'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a9a20b8e75e66e6b",
   "metadata": {},
   "source": [
    "### 3. Final Result\n",
    "All datasets reference the **movies** dataset. A movie is uniquely identified by his **id** and a movie id has multiple occurrences in other datasets. A movie has a title, a tagline, a description, the release year, the duration and a rating. Only the title is mandatory and all the other attributes could be missing."
   ]
  },
  {
   "cell_type": "code",
   "id": "35481461787f2554",
   "metadata": {},
   "source": [
    "movies_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f54fa1742a832d2d",
   "metadata": {},
   "source": [
    "movies_df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f0b9a430d101b37",
   "metadata": {},
   "source": [
    "## Languages"
   ]
  },
  {
   "cell_type": "code",
   "id": "ece358f79ead413e",
   "metadata": {},
   "source": [
    "# Import 'languages.csv' dataset\n",
    "lang_df = pd.read_csv('datasets/languages.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc0e51ab4b81515f",
   "metadata": {},
   "source": [
    "### 1. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd8e821868e23834",
   "metadata": {},
   "source": [
    "lang_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4523d755552d193",
   "metadata": {},
   "source": [
    "lang_df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a75cc482a4a9e58f",
   "metadata": {},
   "source": [
    "lang_df.dtypes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df4400a39ba89b3d",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "id": "567cb4904bd42350",
   "metadata": {},
   "source": [
    "# Rename columns\n",
    "lang_df = lang_df.rename(columns={'id': 'movie_id'})\n",
    "print(f\"Languages dataset columns: {', '.join(lang_df.columns)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9beb77f2bec1fd8",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "lang_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df1df599b18fb36d",
   "metadata": {},
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {lang_df.duplicated().sum()} duplicated rows\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f395fe64e995870",
   "metadata": {},
   "source": [
    "# Setting the category data type for column 'type'\n",
    "print(f\"types: {', '.join(lang_df['type'].unique())}\")\n",
    "lang_df['type'] = lang_df['type'].astype('category')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4a98b5d55e778524",
   "metadata": {},
   "source": "The `type` field has only 3 possible values, so we can set it as a categorical type."
  },
  {
   "cell_type": "markdown",
   "id": "ca1422c0332601d4",
   "metadata": {},
   "source": [
    "### 3. Final Result\n",
    "The languages dataset is directly connected to the movies dataset with the 'movie_id' column. There are more languages rows than movies rows, because a movie can have multiple languages connected. Also, not all movie must have a language defined. A language can be of three types:\n",
    "- *Language*: Could be a generic language associated with the movie, used when there is a single dominant language.\n",
    "- *Primary Language*: Could be the main or original language of the movie.\n",
    "- *Spoken Language*: Could be all the languages actually used in the movie's dialogues."
   ]
  },
  {
   "cell_type": "code",
   "id": "2d753d7a649a7bf0",
   "metadata": {},
   "source": [
    "lang_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d7a9b93f2a82197",
   "metadata": {},
   "source": [
    "lang_df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Actors",
   "id": "9bf3064bc8623942"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'actors.csv' dataset\n",
    "actors_df = pd.read_csv('datasets/actors.csv')"
   ],
   "id": "6a0354ba1a003892",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "2ee737e86929a833"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "actors_df.head()",
   "id": "9a9128792094f433",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1db6e7dafedf88df",
   "metadata": {},
   "source": "actors_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a999b36a00c4f0c7",
   "metadata": {},
   "source": "actors_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "4f0f50dc944f6fc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "actors_df = actors_df.rename(columns={'id': 'movie_id'})\n",
    "print(f\"Actors dataset columns: {', '.join(actors_df.columns)}\")"
   ],
   "id": "6430f51f6a75f330",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9187debc4d1ad51e",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "actors_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Despite the high number of null values in the `role` field, the rows will be maintained because they still contain information about the actor's `name`. An actor without a name is unusable information, so the corresponding rows will be removed."
   ],
   "id": "6c07dfb872bec68b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Removing actors without name\n",
    "no_name = actors_df[actors_df['name'].isna()]\n",
    "actors_df = actors_df.dropna(subset=['name'])\n",
    "no_name"
   ],
   "id": "6c5335a514fd12ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "deb18315a671c8ca",
   "metadata": {},
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {actors_df.duplicated().sum()} duplicated rows\")\n",
    "actors_duplicates = actors_df[actors_df.duplicated(keep=False)].head(6)\n",
    "\n",
    "# Dropping the duplicates\n",
    "actors_df = actors_df.drop_duplicates()\n",
    "\n",
    "actors_duplicates"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Completely duplicated rows are clearly an error and can be removed.",
   "id": "c5e1e46b310a3bde"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Deep Clean",
   "id": "3d6b9eb749421fa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "actors_df['role'].value_counts().head(10)",
   "id": "94c807071b2a6ba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The role column has many \"Self\" role variations let's look more deeply.",
   "id": "c283a206af28fe01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.utils import self_actor_role_keywords\n",
    "\n",
    "# Find self variation\n",
    "result = find_matching(actors_df, 'role', self_actor_role_keywords)\n",
    "print(f\"Rows contains 'self' variations: {result['role'].shape[0]}\")\n",
    "result['role'].value_counts().head()"
   ],
   "id": "a79fddf5cb027c68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There are over 300.000 values that are similar to \"Self\", but many of them contains also other information as \"Self - Presenter\" or \"Self - Guest\". Overwriting all those values could result in a loss of information, so they won't be overwritten in the cleaned dataset, but they might be when visualizing the data for statistical purposes.",
   "id": "4a03dfa2819305ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reset indexing after removing rows\n",
    "actors_df = actors_df.reset_index(drop=True)"
   ],
   "id": "e4282914c42bb2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Final Result\n",
    "The actors dataset is directly connected to the movies dataset and has almost six times the number of rows as the movies dataset. Also, a movie can have no actors connected. The same actor can have multiple occurrences in the dataset because he can appear in more than on movie. <br> An actor is identified solely by his full name, stored in a single field.\n"
   ],
   "id": "563dedd21501ece"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "actors_df.head()",
   "id": "4a2d9fb39fd684d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b17166d2b8653e0",
   "metadata": {},
   "source": "actors_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Countries",
   "id": "f1d9363444a67cae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'countries.csv' dataset\n",
    "countries_df = pd.read_csv('datasets/countries.csv')"
   ],
   "id": "5e192245cdc9b500",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "e2969b68d9823aab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "countries_df.head()",
   "id": "7815e5b02dc6baef",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c10d0df0feda424d",
   "metadata": {},
   "source": "countries_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68a498aed1f33a22",
   "metadata": {},
   "source": "countries_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "5036eeb19736e889"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "countries_df = countries_df.rename(columns={'id': 'movie_id'})\n",
    "print(f\"Countries dataset columns: {', '.join(countries_df.columns)}\")"
   ],
   "id": "5fac7f129517a8a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55f18d2a971d436a",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "countries_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c65f479cfb939c5a",
   "metadata": {},
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {countries_df.duplicated().sum()} duplicated rows\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Final Results\n",
    "The **countries** dataset is directly connected to the movies dataset with the 'movie_id' column. This dataset contains all the countries where the movies were produced.\n"
   ],
   "id": "8fc0403ab681ebc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "countries_df.head()",
   "id": "aaf9ca571009ee3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fe6488ea4524f638",
   "metadata": {},
   "source": "countries_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Crew",
   "id": "1122f4499c98b73b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'crew.csv' dataset\n",
    "crew_df = pd.read_csv('datasets/crew.csv')"
   ],
   "id": "e1d3a171d015fcb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "80892b45436e51e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "crew_df.head()",
   "id": "b488341ae318b3d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85e516c20b098c22",
   "metadata": {},
   "source": "crew_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e9579fa3486f88e",
   "metadata": {},
   "source": "crew_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "ad8721f119cf94d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "crew_df = crew_df.rename(columns={'id': 'movie_id', 'name': 'crew_member_name'})\n",
    "print(f\"Crew dataset columns: {', '.join(crew_df.columns)}\")"
   ],
   "id": "268ff79057a21edb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56a653c79e4f9730",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "crew_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The existing `NaN` value was not removed because it is minimal compared to the overall size of the dataset, and removing it would not significantly impact the analysis. Similarly, values such as *Unknown* or *Anonymous* were kept because they account for less than 0.1% of the data and do not affect the overall results.",
   "id": "653c8210e6e4480b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for duplicate rows\n",
    "print('Duplicated rows:', crew_df.duplicated().sum())\n",
    "crew_duplicates = crew_df[crew_df.duplicated(keep=False)].head()\n",
    "\n",
    "# Dropping the duplicates\n",
    "crew_df = crew_df.drop_duplicates()\n",
    "\n",
    "crew_duplicates"
   ],
   "id": "7f6075c4451752e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Completely duplicated rows are clearly an error and can be removed.",
   "id": "6b9bba4bf607c54f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Deep Clean",
   "id": "b954ac16d395af76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO: deep clean to remove escape from name column",
   "id": "39b9ef5776b26b5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reset indexing after removing rows\n",
    "crew_df = crew_df.reset_index(drop=True)"
   ],
   "id": "8f3cd5fe16853ccf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Final Results\n",
    "The **crew** dataset is connected to the movies dataset through the `movie_id` column. It includes the names of all crew members along with their roles. <br>\n",
    "A crew member can have different roles in the same movies and can appear in more than one movie. <br>\n",
    "A crew member is solely identified by his full name."
   ],
   "id": "2649f725e4082c0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "crew_df.head()",
   "id": "e39e3a8cefbde1e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "704a35689acd277a",
   "metadata": {},
   "source": "crew_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Genres",
   "id": "e85d09f6e1a04068"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'genres.csv' dataset\n",
    "genres_df = pd.read_csv('datasets/genres.csv')"
   ],
   "id": "860a0ee5a5f558d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "17adafa70ee07907"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "genres_df.head()",
   "id": "355d3e1444e6a9c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d81b082bc37242f6",
   "metadata": {},
   "source": "genres_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "143ecf4fe158fba2",
   "metadata": {},
   "source": "genres_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "1aff4674837a5d81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "genres_df = genres_df.rename(columns={'id': 'movie_id'})\n",
    "print(f\"Genres dataset columns: {', '.join(genres_df.columns)}\")"
   ],
   "id": "fdcab4c2d97ac491",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8e51ba8b0004763",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "genres_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3646eb6aa8a294c3",
   "metadata": {},
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {genres_df.duplicated().sum()} duplicated rows\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f4ab9550c0d65192",
   "metadata": {},
   "source": [
    "# Setting the correct type for columns\n",
    "genres_list = list(genres_df[\"genre\"].unique())\n",
    "print(f'There are {len(genres_list)} genres in the dataset: {\", \".join(genres_list)}')\n",
    "\n",
    "genres_df['genre'] = genres_df['genre'].astype('category')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Final Results\n",
    "The **genres** dataset is connected to the movies dataset through the 'movie_id' column. A movie can have multiple genres.\n"
   ],
   "id": "c7e984ddf81ccb1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "genres_df.head()",
   "id": "e8212362a24e246c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bab939cf7be6dcaa",
   "metadata": {},
   "source": "genres_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed9881e2ff2d6321",
   "metadata": {},
   "source": [
    "# Print clean dataset to new csv file\n",
    "if PRINT_CSV:\n",
    "    genres_df.to_csv('clean_datasets/genres.csv')\n",
    "\n",
    "genres_df = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Posters",
   "id": "eb596a96e8ea190b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'posters.csv' dataset\n",
    "posters_df = pd.read_csv('datasets/posters.csv')"
   ],
   "id": "403fd2064babd235",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "e4940c54fc49f25c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "posters_df.head()",
   "id": "9871771eeedfc55c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e493780822572d4",
   "metadata": {},
   "source": "posters_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8606883b437702d9",
   "metadata": {},
   "source": "posters_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "dd9d2bacbaee4b45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "posters_df = posters_df.rename(columns={'id': 'movie_id', 'link': 'poster_link'})\n",
    "print(f\"Posters dataset columns: {', '.join(posters_df.columns)}\")"
   ],
   "id": "2182ed33df60f466",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee99715a7770203d",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "posters_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63dcee20ac047ce7",
   "metadata": {},
   "source": [
    "# Removing null rows\n",
    "posters_df = posters_df.dropna()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It was decided to remove the `NaN` values as they do not contribute meaningful information to the dataset and could hinder data consistency and analysis.",
   "id": "90fceec99a696336"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {posters_df.duplicated().sum()} duplicated rows\")"
   ],
   "id": "a4ba1493c388ea5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47c6dd59eb2d0166",
   "metadata": {},
   "source": [
    "# Check if a movie can have more than 1 poster\n",
    "id_duplicates = posters_df['movie_id'].duplicated().any()\n",
    "\n",
    "if id_duplicates:\n",
    "    print(\"There are duplicates in the 'movie_id' column.\")\n",
    "else:\n",
    "    print(\"There are no duplicates in the 'movie_id' column.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The relationship between the **posters** dataset and the **movies** dataset must be One-to-One, allowing us to consider merging the two datasets.",
   "id": "571ae0ea4591d425"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for invalid links\n",
    "link_regex = r'\\bhttps?:\\/\\/(?:www\\.)?[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}(?:\\/[^\\s]*)?'\n",
    "\n",
    "all_valid = posters_df['poster_link'].str.contains(link_regex, na=False).all()\n",
    "\n",
    "if all_valid:\n",
    "    print(\"All links are valid.\")\n",
    "else:\n",
    "    print(\"Some rows contains invalid links\")"
   ],
   "id": "59102f00154663d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Final Results",
   "id": "f0b7bd4f467b7d57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "posters_df.head()",
   "id": "4f205e31002afb7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2bbcf090c4f37230",
   "metadata": {},
   "source": "posters_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a5625b2b9b37a59",
   "metadata": {},
   "source": [
    "# TODO: Merging the datasets on 'id' from 'movies' and 'movie_id' from 'posters'\n",
    "# merged_df = pd.merge(movies_df, posters_df, left_on='id', right_on='movie_id', how='left')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b00a8511b531e0cb",
   "metadata": {},
   "source": [
    "if PRINT_CSV:\n",
    "    posters_df.to_csv('clean_datasets/posters.csv')\n",
    "\n",
    "posters_df = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Releases",
   "id": "e5c776fed4df7b46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'release.csv' dataset\n",
    "releases_df = pd.read_csv('datasets/releases.csv')"
   ],
   "id": "452f3fa61572b07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "46ae974f7d414208"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "releases_df.head()",
   "id": "29d4f97bf53cf2e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4229fdeb2ec0df4",
   "metadata": {},
   "source": "releases_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c3f65a9f26b8107",
   "metadata": {},
   "source": "releases_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "571f2114cfb9ed7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "releases_df = releases_df.rename(columns={'id': 'movie_id', 'type': 'distribution_format'})\n",
    "print(f\"Release dataset columns: {', '.join(releases_df.columns)}\")"
   ],
   "id": "fffde7a39f606830",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f968df32d23f212",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "releases_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It's fine for the dataset to have null values only in the 'rating' field, we can keep the data without that information as the absence of ratings doesn't affect the overall analysis or integrity of the other data columns.",
   "id": "663da19b56ef9c19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {releases_df.duplicated().sum()} duplicated rows\")"
   ],
   "id": "c6d04c3f8349ce7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bd49ddafbd907a9",
   "metadata": {},
   "source": [
    "# Check for alternative null values in the dataset\n",
    "releases_df[(releases_df['rating'] == \"0\") & (~releases_df['country'].isin([\"Germany\", \"Austria\", \"Switzerland\"]))].head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We initially checked the value `0` in the dataset, assuming it might represent a null or missing value. However, we discovered that in Germany, Austria, and Switzerland, the `0` rating has a meaningful interpretation, indicating that the film is suitable for all audiences, including children. For the remaining countries, it is possible that the `0` rating is an error, but since it appears only 70 times in a dataset of 1,332,782 rows, we deemed it unnecessary to remove or correct these entries.",
   "id": "2f00d4768c79e451"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setting the correct type for the columns\n",
    "releases_df['date'] = pd.to_datetime(releases_df['date'], format='%Y-%m-%d')\n",
    "releases_df['distribution_format'] = releases_df['distribution_format'].astype('category')"
   ],
   "id": "2321d27b8ed7276d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Final Results\n",
    "The **release** dataset is linked to the movies dataset via the 'movie_id' column. It contains details about the movies' releases around the world."
   ],
   "id": "1ea61bee9191c465"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "releases_df.head()",
   "id": "e0be4cba5f2b3859",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6bf754e207c33c8",
   "metadata": {},
   "source": "releases_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0ca164238628799",
   "metadata": {},
   "source": [
    "if PRINT_CSV:\n",
    "    releases_df.to_csv('clean_datasets/releases.csv')\n",
    "\n",
    "releases_df = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Studios",
   "id": "9737e986e51d2cfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'studios.csv' dataset\n",
    "studios_df = pd.read_csv('datasets/studios.csv')"
   ],
   "id": "3d2689ce87ad8b1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "28637961eba451d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "studios_df.head()",
   "id": "4fee13f9ba916f6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a88021e9ebb0065c",
   "metadata": {},
   "source": "studios_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bbf42bcb0f1fb08",
   "metadata": {},
   "source": "studios_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "74f2241fe9949baf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "studios_df = studios_df.rename(columns={'id': 'movie_id'})\n",
    "print(f\"Studios dataset columns: {', '.join(studios_df.columns)}\")"
   ],
   "id": "ef2ca86c4030239",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be17f510fb844ba0",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "studios_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8595684e442f49a9",
   "metadata": {},
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {studios_df.duplicated().sum()} duplicated rows\")\n",
    "studios_df[studios_df.duplicated(keep=False)].head(6)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b42b2747620c49e5",
   "metadata": {},
   "source": [
    "studios_df = studios_df.dropna()\n",
    "studios_df = studios_df.drop_duplicates()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can safely remove the null and the duplicates values from the dataset, as they were not meaningful and irrelevant",
   "id": "b47d4f5c80c11489"
  },
  {
   "cell_type": "markdown",
   "id": "9fd5d15b2326c93d",
   "metadata": {},
   "source": [
    "### 3. Final Results\n",
    "The **studios** dataset is connected to the movies dataset through the 'movie_id' column. It lists all the studios involved in each movie, allowing a movie to be associated with multiple studios and a studio to collaborate on multiple movies."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "studios_df.head()",
   "id": "8f103f1b74015b1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6bbbdea78e8941f9",
   "metadata": {},
   "source": "studios_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a6bfeaf84401a35",
   "metadata": {},
   "source": [
    "if PRINT_CSV:\n",
    "    studios_df.to_csv('clean_datasets/studios.csv')\n",
    "\n",
    "studios_df = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Themes",
   "id": "e8ad60965cb8f312"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'themes.csv' dataset\n",
    "themes_df = pd.read_csv('datasets/themes.csv')"
   ],
   "id": "467abef3146c2450",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "d9ba7956130c0647"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "themes_df.head()",
   "id": "36cfa6d2ecba36c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69df8bf8d4af08b6",
   "metadata": {},
   "source": "themes_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae680921860473c0",
   "metadata": {},
   "source": "themes_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "ef8edd02f93d29df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "themes_df = themes_df.rename(columns={'id': 'movie_id'})\n",
    "print(f\"Themes dataset columns: {', '.join(themes_df.columns)}\")"
   ],
   "id": "ed07fc6b8bf6673e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d304eca9061e808",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "themes_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2084d91873e547a3",
   "metadata": {},
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {themes_df.duplicated().sum()} duplicated rows\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab2b77ce8ed56bcd",
   "metadata": {},
   "source": [
    "# Check for invalid themes\n",
    "themes_df['theme'].value_counts().head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Final Results\n",
    "The **themes** dataset is linked to the movies dataset via the 'movie_id' column. It describes a movie with few, standard phrases."
   ],
   "id": "3fec6a74b9d74921"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "themes_df.head()",
   "id": "d52e79450b746a17",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3acdf4455cdc7109",
   "metadata": {},
   "source": "themes_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "53b93e65c67cf8a2",
   "metadata": {},
   "source": [
    "if PRINT_CSV:\n",
    "    themes_df.to_csv('clean_datasets/themes.csv')\n",
    "    \n",
    "themes_df = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The Oscar Awards",
   "id": "c14a45c6bd1d9f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'the_oscar_awards.csv' dataset\n",
    "oscars_df = pd.read_csv('datasets/the_oscar_awards.csv')"
   ],
   "id": "f26b0b3d14b0f52e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "d03f7cfdd91ab9e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "oscars_df.head()",
   "id": "fccabeaf5be196d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29e89700e94bb439",
   "metadata": {},
   "source": "oscars_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "efceb3c1ee68ef58",
   "metadata": {},
   "source": "oscars_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "741dd394f5e0af2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "oscars_df = oscars_df.rename(columns={'name': 'nominee_name', 'film': 'nominated_film', 'winner': 'is_winner'})\n",
    "print(f\"Oscar dataset columns: {', '.join(oscars_df.columns)}\")"
   ],
   "id": "7b604a36fcf4142e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d93f7491d1b2ef61",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "oscars_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "307b81116fc86d32",
   "metadata": {},
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"There are {oscars_df.duplicated().sum()} duplicated rows\")\n",
    "oscars_df[oscars_df.duplicated(keep=False)].head(6)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Duplicates are retained because, in music categories, the same artists can receive identical nominations for different songs, with the song titles not specified in the dataset",
   "id": "751e26f4f6f5f6f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check the consistency between year_film and year_ceremony\n",
    "inconsistent_years_df = oscars_df[oscars_df['year_film'] > oscars_df['year_ceremony']]\n",
    "\n",
    "if inconsistent_years_df.empty:\n",
    "    print(\"The years fields are always consistent (ceremony year always greater than year film)\")\n",
    "else:\n",
    "    inconsistent_years_df.head()"
   ],
   "id": "cc4bc676259f0b43",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d29d2335bbf5f57",
   "metadata": {},
   "source": [
    "# Check for multiple winner possibilities\n",
    "from utils.utils import special_oscar_awards\n",
    "\n",
    "# Exclude rows where the 'category' is in the special_oscar_awards list\n",
    "filtered_oscars = oscars_df[~oscars_df['category'].isin(special_oscar_awards)]\n",
    "\n",
    "# Find groups with more than one winner\n",
    "multiple_winners = filtered_oscars.groupby(['year_ceremony', 'category']).filter(\n",
    "    lambda x: x['is_winner'].sum() > 1\n",
    ")\n",
    "\n",
    "# Keep only the rows where 'is_winner' is True\n",
    "multiple_winners = multiple_winners[multiple_winners['is_winner'] == True]\n",
    "multiple_winners.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Displaying multiple winners (including draws), as we want to keep all winners in case of a draw in the same category (1969 Best Actress, or 1932 Best Actor). <br>\n",
    "We decided to exclude some special awards, like the Jean Hersholt Humanitarian Award, because they are often less relevant to films and typically have multiple recipients. These awards are not traditional competitive awards but rather honorary recognitions."
   ],
   "id": "c24d5696c99a5999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setting the correct type for columns\n",
    "oscars_df['category'] = oscars_df['category'].astype('category')"
   ],
   "id": "568c18ca79e97a9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Final Results",
   "id": "71c3be3ed819e979"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "oscars_df.head()",
   "id": "a38f7f0f12f92b9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac992bfef9078cde",
   "metadata": {},
   "source": "oscars_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70d9b4555f7f7027",
   "metadata": {},
   "source": [
    "if PRINT_CSV:\n",
    "    oscars_df.to_csv('clean_datasets/the_oscar_awards.csv')\n",
    "\n",
    "oscars_df = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Rotten Tomatoes Reviews",
   "id": "a670a475ea20ed78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import 'rotten_tomatoes_reviews' dataset\n",
    "reviews_df = pd.read_csv('datasets/rotten_tomatoes_reviews.csv')"
   ],
   "id": "b3d0f18e491ab115",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data Understanding",
   "id": "a790ee8417635725"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reviews_df.head()",
   "id": "ca8a2a77b4bf060c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e959042f66953cdb",
   "metadata": {},
   "source": "reviews_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f729775e5075501",
   "metadata": {},
   "source": "reviews_df.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Data Cleaning",
   "id": "48154fd38808d4d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "reviews_df = reviews_df.rename(columns={'review_type': 'type', 'review_score': 'score', 'review_date': 'date', 'review_content': 'content', 'top_critic': 'is_top_critic'})\n",
    "print(f\"Rotten Tomatoes Reviews dataset columns: {', '.join(reviews_df.columns)}\")"
   ],
   "id": "434b3feddc2528b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f35d276353417a37",
   "metadata": {},
   "source": [
    "# Check for null values\n",
    "reviews_df.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking on Rotten Tomatoes website is fine having the publisher and critic name and content as null values.",
   "id": "ce5b9a2709c7ee6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for duplicate rows\n",
    "filtered_df = reviews_df[reviews_df['critic_name'].notna()]\n",
    "filtered_df = filtered_df[filtered_df.duplicated(keep=False)]\n",
    "\n",
    "reviews_df = reviews_df.drop(reviews_df[reviews_df['critic_name'].isna()].index)\n",
    "\n",
    "filtered_df"
   ],
   "id": "576cd57651f54647",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There are many duplicate reviews in the datasets. Looking closely is actually possible to have more reviews for the same movie that have the same publisher and with the author not specified. Those rows will be excluded from the total count of duplicate rows and will not be removed. All other duplicate rows will be removed.",
   "id": "be65c7711e299c87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setting the correct type for columns\n",
    "reviews_df['type'] = reviews_df['type'].astype('category')\n",
    "reviews_df['date'] = pd.to_datetime(reviews_df['date'], format='%Y-%m-%d')"
   ],
   "id": "d6b383e9c3e0f4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Final Result",
   "id": "dd1f25f9e8d15aea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reviews_df.head()",
   "id": "3dc1b542d28cde61",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ccca9ccb161d93",
   "metadata": {},
   "source": "reviews_df.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86d8854260261307",
   "metadata": {},
   "source": [
    "# Print clean dataset to new csv file\n",
    "if PRINT_CSV:\n",
    "    reviews_df.to_csv('clean_datasets/reviews.csv')\n",
    "\n",
    "reviews_df = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving the cleaned datasets",
   "id": "2abfaa9286ea0587"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print the clean datasets to new csv files TODO\n",
    "if PRINT_CSV:\n",
    "    movies_df.to_csv('clean_datasets/movies.csv')\n",
    "    lang_df.to_csv('clean_datasets/languages.csv')\n",
    "    actors_df.to_csv('clean_datasets/actors.csv')\n",
    "    countries_df.to_csv('clean_datasets/countries.csv')\n",
    "    crew_df.to_csv('clean_datasets/crew.csv')"
   ],
   "id": "d4464b09d031d772",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
